---
title: "Tarea 6: regularización ridge"
output: html_notebook
---


En este ejemplo trabajaremos con un 
[ejemplo de Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques), 
en donde queremos predecir el precio listado de una casa dependiendo de 
varias características.

El diccionario de datos está en el archivo *data_description.txt*

```{r}
library(tidyverse)
library(glmnet)
datos <- read_csv("./tarea_6_datos/data_train.csv", na= "") %>%
    select(-GarageYrBlt, -LotFrontage, -MasVnrArea, -GarageYrBlt, -MoSold, -PoolQC)
datos$MSSubClass <- factor(datos$MSSubClass)
```


### Preprocesamiento 

Necesitamos hacer varios pasos de limpieza y preprocesamiento de datos.
Aquí solo haremos una limpieza y transformación parcial para propósitos de
nuestro ejemplo.

En primer lugar, nota que muchas de estas variables son categóricas. En los casos donde hay
datos no disponibles (NA), estas se cuentan como una categoría más, por ejemplo:

```{r}
table(datos$Alley)
```

En este caso, la categoría NA indica que la casa no tiene acceso por callejón. Igual que en el ejemplo
del Titanic, convertimos estas variables con *dummy coding*, o *one hot encoding*.

Podemos usar la función *model.matrix* para hacer este preprocesamiento:

```{r}
x_datos <- model.matrix(SalePrice ~ ., datos %>% select(-Id))
x_datos <- x_datos[, -1] # quitamos columna de unos
y <- datos$SalePrice
```

Por ejemplo, la variable categórica *Alley* (con 3 niveles) corresponde ahora
a dos columnas de variables binarias:

```{r}
x_datos[c(20,21,22,31), c('AlleyNA','AlleyPave')]
```

que puedes comparar con la variable original

```{r}
datos[c(20,21,22,31), "Alley"]
```

Otro ejemplo es la variable *MSZoning*, cuyas categorías son:

```{r}
table(datos$MSZoning)
```

y corresponde a las nuevas variables

```{r}
x_datos[1:10, 15:18]
```

Aquí mostramos las variables que usaremos para nuestros modelos:

```{r}
colnames(x_datos)
```

Finalmente, la variable que queremos predecir es
*SalePrice*:

```{r}
qplot((datos$SalePrice))
```

**Nota: veremos más adelante más pasos de preprocesamiento para
mejorar considerablemente el modelo que obtenemos abajo.**

### Regresión ridge

Separamos un conjunto de entrenamiento y uno de prueba (1/2 aproximadamente)

Notemos que en el siguiente codigo se debía corregir el -1 de los id's pues esta columna ya había sido eliminada.
```{r}
set.seed(9911)
indices_entrena <- sample(1:nrow(x_datos), 700)
x_ent <- x_datos[indices_entrena,] # primera columna es de 1's, la quitamos
y_ent <- y[indices_entrena] / 1000 # miles de dólares
x_pr <- x_datos[-indices_entrena,]
y_pr <- y[-indices_entrena] / 1000 #miles de dólares
```

1. Utiliza la función glmnet para ajustar modelos lineales para 
valores de regularización. Utiliza la siguiente sucesión de
valores $\lambda$ de regularización ridge:

```{r}
lambda <- exp(seq(-10, 10, 1))
lambda
```

```{r}
# completa los parámetros que faltan para ajustar los modelos:
mod_ridge <- glmnet(y = y_ent, x = x_ent, alpha = 0, family = "gaussian", 
                lambda = lambda)
```

Grafica la traza de los coeficientes:

```{r}
plot(mod_ridge, xvar= "lambda")
```

- ¿Qué pasa con los coeficientes cuando aumenta el valor de lambda? 
  Convergen a 0
- ¿Todos los coeficientes se acercan siempre al valor 0 cuando aumentamos
la regularización?
  si, con excepción de beta1
- ¿Por qué parece ser que los coeficientes tienen valores casi constantes 
para valores suficientemente bajos de lambda?
  porque esta penalizando mucho los valores de las betas conforme hacemos crecer lambda

2. Selecciona el valor de regularización usando validación
cruzada con la función *cv.glmnet*:

```{r}
# completa los parámetros que faltan:
cv_mod_1 <- cv.glmnet(y = y_ent , x = x_ent, alpha = 0, family = "gaussian",
                      lambda = lambda, nfolds = 10)
plot(cv_mod_1)
```

¿Qué valores de la regularización dan los errores más bajos 
(según la estimación de validación cruzada?)

3 y 4

3. Selecciona un modelo con baja regularización, con el valor óptimo
según validación cruzada, y otro con mucha regularización (utiliza las lambdas
mostradas abajo).
Evalúa el
error de predicción (raíz de error cuadrático media) 
según la muestra de prueba que separamos arriba:

```{r}
# rellena tres valores, uno con muy baja regularización , uno con regularización
#óptima según validación cruzada, y otro con demasiada regularización:
lambda_pred <- c(lambda[1] ,lambda[15] , lambda[20])
lambda_pred
```

Calcula errores de prueba

```{r}
preds_1 <- predict(mod_ridge, newx = x_pr, s = lambda_pred[1])
preds_2 <- predict(mod_ridge, newx = x_pr, s = lambda_pred[2])
preds_3 <- predict(mod_ridge, newx = x_pr, s = lambda_pred[3])
sqrt(mean((preds_1 - y_pr)^2))
sqrt(mean((preds_2 - y_pr)^2))
sqrt(mean((preds_3 - y_pr)^2))
```

- ¿Qué modelo tiene el error más bajo de prueba? ¿Por qué esperarías esto?

El de lambda optimo, porque al estamos minimizando el error cuadratico + la regularización; para este caso usamos la lambda que mminimiza esta suma.

Grafica predicciones del modelo con menor error contra los valores observados

```{r}
mod_1_rid<-as.data.frame(cbind(y_pr,preds_3))
colnames(mod_1_rid)<-c("Valor real","Ajustado")
ggplot(mod_1_rid, aes(x=preds_2,y=y_pr))+geom_point()+
  geom_smooth()

# Haz tu gráfica aquí
```


4. Compara los coeficientes del modelo menos regularizado con el de
regularización óptima


```{r}
coefs_reg_baja <- predict(mod_ridge, 
                          s = lambda_pred[1], type= "coefficients")
coefs_reg_baja <- coefs_reg_baja[-1,1] # tomamos la primera columna y quitamos intercept
# rellena aquí
coefs_reg_opt <- predict(mod_ridge, s=lambda_pred[2],type = "coefficients")
coefs_reg_opt <- coefs_reg_opt[-1,1]    
# ahora grafica estos coeficientes en una gráfica x-y:
coeficientes<-as.data.frame(cbind(coefs_reg_baja,coefs_reg_opt))
colnames(coeficientes)<-c("Baja","Optima")
ggplot(coeficientes, aes(x= Baja, y=Optima))
```

- ¿Qué puedes decir acerca de la dispersión de los coeficientes del modelo
con baja regularización en comparación al de regularización media? ¿Cuál
es el rango de los coeficientes del modelo con baja regularización? 

tienen una disperción más alta.

5. Compara algunos coeficientes de dos modelos, el de regularización baja con
uno de regularización óptima según validación cruzada

Por ejemplo, compara los coeficientes relacionados con el garage (tipo, terminados,
Calidad, Condición, coches y área):

```{r}
nombres <- rownames(as.data.frame(coefs_reg_baja))
coef_garage_baja <- coefs_reg_baja[str_detect(nombres, "Garage")]
coef_garage_baja
```

- ¿Qué efecto puede tener esta variable en tus predicciones? Considera que el tamaño
de los coeficientes está en miles de dólares,

Tienen un rango muy amplio, incluso acercandose a la mediana, por lo que haría que nuestras estimaciones variaran mucho.

- ¿Cuál es el valor mediano de las casas en el conjunto de entrenamiento (y)? ¿Los
efectos del inciso anterior te parecen razonables?

162. No ya que la presencia de alguna de estas variables llevaria a 0 la estimación.

```{r}
median(y_pr)
min(coef_garage_baja)
max(coefs_reg_baja)
```
Repite para regularización óptima según validación cruzada:

```{r}
nombres <- rownames(as.data.frame(coefs_reg_opt))
coef_garage_opt <- coefs_reg_opt[str_detect(nombres, "Garage")]
coef_garage_opt
```


Observamos claramente que son más pequeños los coeficientes y tienen sentido vs la escala de nuestra variable respuesta.

```{r}
# calcula para los coeficientes del modelo más regularizado
coefs_reg_alta <- predict(mod_ridge, s=lambda_pred[3],type = "coefficients")
coefs_reg_alta <- coefs_reg_alta[-1,1]
coefs_reg_alta
```

- ¿Qué efecto puede tener esta variable en tus predicciones? Considera que el tamaño
de los coeficientes está en miles de dólares?

```{r}
min(coefs_reg_alta)
max(coefs_reg_alta)
```
Son muy pequeños,  lo que haría que difícilmente bajen o suban nuestras estimaciones, es decir el modelo es muy parecido a una constante.


- ¿Cuál es el valor mediano de las casas en el conjunto de entrenamiento (y)? ¿Los
efectos del inciso anterior te parecen razonables?

```{r}
median(y_pr)
```
No, puesto que no movería a beta 1


